# 隐私计算任务生成


## 1. 计算流程的抽象

目前Delta中，隐私计算任务包含两种类型，横向联邦学习与横向联邦统计。虽然两种任务类型的计算的内容区别很大，但是计算的流程是类似的：
都是将计算任务分发到各个数据持有者的终端上进行计算，然后再聚合他们的计算结果，得到最终的全局结果。

我们可以看出，这个流程与Map Reduce是类似的：在各个数据持有者终端上进行计算的过程对应map，聚合他们的计算结果，得到全局结果的过程对应reduce。
在这里，我们将持有数据、执行map操作的称为客户端，将发起计算任务、执行reduce操作的称为服务端。
虽然横向联邦的计算流程与Map Reduce类似，但是它并不是真正的Map Reduce，主要的不同点有两点：

1. 横向联邦的计算流程中，map与reduce之间使用的是安全聚合，只能得到聚合后的结果
（以目前的安全聚合算法来说，就是各个客户端结果的加法和），并不能直接得到各个客户端的计算结果
2. 横向联邦的计算流程中，数据归各个客户端分别持有，所以传统Map Reduce中需要在各个客户端之间进行数据交换、重排序的操作都不能够实现

综上，如果我们将客户端上进行的计算称为map，安全聚合称为aggregate，在服务端上进行的计算称为reduce，那么
横向联邦的计算流程，就可以抽象为：

$$map -> aggregate -> reduce$$

## 2. 计算任务的抽象

上面我们已经看到了，横向联邦的计算流程可以抽象为$map -> aggregate -> reduce$，那么一个横向联邦的计算任务
是不是也可以抽象为$map -> aggregate -> reduce$呢？
并不是，一个横向联邦的计算任务，会更加复杂一点。

上面抽象的计算流程，只对应了一次Map Reduce，而无论是横向联邦学习还是统计，稍微复杂一点的计算逻辑都不可能只对应于一次Map Reduce，
大部分都会对应于多次Map Reduce。当然，我们可以把任务的粒度就抽象到一次Map Reduce，但是这就需要让用户把一个完整的计算逻辑拆成
多个任务，分别提交，非常的不友好。所以，更合理的设计是一次任务包含多次Map Reduce。

那是不是一个横向联邦任务，就是多组Map Reduce呢？并不完全是。我们需要注意到，横向联邦任务中，数据是归各个客户端分别持有的，
某个客户端是否加入任务，是由客户端自身决定的；同时，横向联邦任务对于参与的客户端数量也是有要求的，根据安全聚合算法的不同，会有
一个参与数量的下限和上限。所以这就于传统的Map Reduce不同，横向联邦任务发起后，必须等待网络中的各个客户端响应，有足够多的客户端加入后，
才能开始执行任务。如果响应的客户端过多的话，还需要从中选择出一部分客户端加入任务，其他未被选择的客户端则不能参与计算。
我们将这样一个等待客户端响应并选择一部分客户端加入任务的过程，称为$select$。

那么，这个$select$过程，是不是每个任务开始时，执行一次呢？并不是这样，我们需要在每次Map Reduce开始前都进行一次$select$操作。
这样做的理由是，一个任务，可以包含多个Map Reduce，整个流程可能很长，这个过程中，可能有客户端会突然下线（如果客户端是手机，这种情况很常见），
也有客户端会在任务中途上线，那么，只在任务开始时$select$一次，对于长流程的任务来说，可能就太少了。所以，我们选择在每次Map Reduce之前，
都进行一次$select$操作。也就是说，每次$select$操作中选出的客户端，都只对应于一次Map Reduce，只需要完成这一次Map Reduce即可。
这样每个客户端的压力小了很多，不再需要保持长时间的在线，同时对于任务发起者而言，也不会出现任务执行过程中，客户端越来越少的情况。

那么我们将一个$select -> map -> aggregate -> reduce$的过程，称为一轮，也就是一个$Round$。
一个横向联邦计算任务的流程，就可以抽象为多个$Round$，也就是：

$$Start -> Round 1 -> Round 2 -> ... -> Round N -> Finish$$

当然，一个完整的横向联邦计算任务，除了流程之外，还应该包含输入和输出。任务的输入，可以分为两类:

1. 一类是外部的输入，也就是各个客户端
持有的数据，这些数据，在任务定义的过程中并不能获取到他们的值，只能在运行时获取，因此在定义任务时，要采用声明式的方式来定义这些输入；
2. 另一类是任务自带的输入，比如说联邦学习中模型的初始权重，联邦统计中用户使用的一些常量、字面量等，这些值在定义任务时，值就已经明确了。

关于任务的输出，不同的任务类型，有不同的输出。具体来说，联邦学习任务的输出就是固定的，是训练好的模型权重；联邦统计的任务输出就不固定了，
用户在编写任务时，可以根据需要来定义不同的任务输出。但是有一点需要注意的是，任务最后的输出一定要是安全的，不能泄露客户端数据的隐私，
也就是说，最后输出的值一定是要通过reduce操作生成的、“归并”过的值。

所以，对于Delta来说，需要做的就是将用户编写的任务逻辑代码（横向联邦学习，横向联邦统计），转化为上述的一个又一个$Round$的形式，
并实现相应的客户端、服务端和安全聚合算法，用来执行每个$Round$中的$map$、$reduce$、$aggregate$和$select$操作。
