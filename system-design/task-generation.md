# 横向联邦任务框架

Delta中的横向联邦任务包括了联邦学习和联邦统计两种。联邦学习用于机器学习模型的训练，联邦统计用于计算数据集的统计结果。虽然两种任务类型的计算的内容区别很大，但是计算的流程是类似的。在Delta中，两种任务都是按照统一的横向联邦任务框架执行。本文首先介绍抽象的联邦任务执行的统一框架，然后再针对具体的联邦学习和联邦统计两种任务，分别介绍其在联邦任务执行框架下不同的实现方式。

### Delta Task计算流程

横向联邦任务框架将Delta Task拆分为多个计算单元的组合，每个计算单元称为一轮（`Round`），每一轮都是完全独立的计算，参与者要在这一轮开始时选择是否加入计算，并执行本地计算，然后将本地生成的用于安全聚合的结果发送到任务发起方，由任务发起方完成最终的计算结果生成。

Delta的横向联邦任务框架参考了`MapReduce`的计算流程，每个计算单元`Round`包括`Select`，`Map`，`Aggregate`，`Reduce`四步。

#### Select - 参与者选取

Delta Task的定义中，包括对参与计算的节点数的限制，比如最少需要几个节点，最多允许几个节点。因此在执行任务之前，需要节点报名参加计算，然后任务发起者在报名者中选择符合条件的参与者，进入到下一步的计算中。

在Delta的设计中，参与者选取在每一个最小计算单元，一个`Round`，进行前都要重新进行一次。这是因为一个任务一般会包含很多个`Round`，整个计算流程需要的时间很长。这个过程中，可能有客户端会突然下线（如果客户端是手机，这种情况很常见）， 也有客户端会在任务中途上线。那么，只在任务开始时select一次，就会导致流程中不断有节点掉线，参与者越来越少，任务就无法执行下去了。所以我们选择在每个`Round`开始时都进行一次`Select`操作。这样每个客户端的压力小了很多，不再需要保持长时间的在线，同时对于任务发起者而言，也不会出现任务执行过程中，客户端越来越少的情况。

#### Map - 本地计算

确定了本轮计算的参与者后，本轮计算就正式开始了。在第一个阶段`Map`中，Delta Task的执行逻辑和`MapReduce`中的`Map`是一致的。各个节点在本地数据集上各自完成任务定义中的计算逻辑，得到本地的计算结果。

Map中的计算逻辑完全在节点本地执行，得到的计算结果也不会对外发送，数据仍然是安全的。

#### Aggregate - 安全聚合

在`Aggregate`阶段，各个节点通过安全聚合算法，生成本地数据的可对外分享结果。这一步的核心是保证每个节点对外分享的结果，无法反推出任何私密的原始数据或者原始统计结果。只有将多个节点的数据求和，得到多个节点的联合统计结果。

`Aggregate`阶段对应于`MapReduce`中的`Shuffle/Sort`阶段。在`MapReduce`的流程中，这一步是节点间交换原始数据，对数据进行排序，为下一步的结果聚合做准备。但是在Delta的任务执行中，为了保证单个节点的数据隐私，不能在节点间直接交换数据，这一步只能通过加密的安全聚合算法，得到`Map`阶段执行结果的全节点求和。然后将求和结果用于下一步的`Reduce`阶段。

以最粗略的方式来看安全聚合的流程，就是各个节点对自己的`Map`计算结果进行一个特殊的"掩码/加密"操作，然后发送给任务发起方。任务发起方收到所有节点的掩码结果进行相加，就得到了多节点原始数据的求和结果。

Delta中的安全聚合使用了区块链进行任务协调，以保证计算结果的可信性。详细的链上安全聚合流程，请参考这篇文章：

{% content-ref url="secure-aggregation-on-blockchain.md" %}
[secure-aggregation-on-blockchain.md](secure-aggregation-on-blockchain.md)
{% endcontent-ref %}

#### Reduce - 结果生成



我们可以看出，这个流程与Map Reduce是类似的：在各个数据持有者终端上进行计算的过程对应map，聚合他们的计算结果，得到全局结果的过程对应reduce。 在这里，我们将持有数据、执行map操作的称为客户端，将发起计算任务、执行reduce操作的称为服务端。 虽然横向联邦的计算流程与Map Reduce类似，但是它并不是真正的Map Reduce，主要的不同点有两点：

1. 横向联邦的计算流程中，map与reduce之间使用的是安全聚合，只能得到聚合后的结果 （以目前的安全聚合算法来说，就是各个客户端结果的加法和），并不能直接得到各个客户端的计算结果
2. 横向联邦的计算流程中，数据归各个客户端分别持有，所以传统Map Reduce中需要在各个客户端之间进行数据交换、重排序的操作都不能够实现

综上，如果我们将客户端上进行的计算称为map，安全聚合称为aggregate，在服务端上进行的计算称为reduce，那么 横向联邦的计算流程，就可以抽象为：

map -> aggregate -> reduce

## 2. 计算任务的抽象

上面我们已经看到了，横向联邦的计算流程可以抽象为map -> aggregate -> reduce，那么一个横向联邦的计算任务 是不是也可以抽象为map -> aggregate -> reduce呢？ 并不是，一个横向联邦的计算任务，会更加复杂一点。

上面抽象的计算流程，只对应了一次Map Reduce，而无论是横向联邦学习还是统计，稍微复杂一点的计算逻辑都不可能只对应于一次Map Reduce， 大部分都会对应于多次Map Reduce。当然，我们可以把任务的粒度就抽象到一次Map Reduce，但是这就需要让用户把一个完整的计算逻辑拆成 多个任务，分别提交，非常的不友好。所以，更合理的设计是一次任务包含多次Map Reduce。

那是不是一个横向联邦任务，就是多组Map Reduce呢？并不完全是。我们需要注意到，横向联邦任务中，数据是归各个客户端分别持有的， 某个客户端是否加入任务，是由客户端自身决定的；同时，横向联邦任务对于参与的客户端数量也是有要求的，根据安全聚合算法的不同，会有 一个参与数量的下限和上限。所以这就于传统的Map Reduce不同，横向联邦任务发起后，必须等待网络中的各个客户端响应，有足够多的客户端加入后， 才能开始执行任务。如果响应的客户端过多的话，还需要从中选择出一部分客户端加入任务，其他未被选择的客户端则不能参与计算。 我们将这样一个等待客户端响应并选择一部分客户端加入任务的过程，称为select。

那么，这个select过程，是不是每个任务开始时，执行一次呢？并不是这样，我们需要在每次Map Reduce开始前都进行一次select操作。 这样做的理由是，一个任务，可以包含多个Map Reduce，整个流程可能很长，这个过程中，可能有客户端会突然下线（如果客户端是手机，这种情况很常见）， 也有客户端会在任务中途上线，那么，只在任务开始时select一次，对于长流程的任务来说，可能就太少了。所以，我们选择在每次Map Reduce之前， 都进行一次select操作。也就是说，每次select操作中选出的客户端，都只对应于一次Map Reduce，只需要完成这一次Map Reduce即可。 这样每个客户端的压力小了很多，不再需要保持长时间的在线，同时对于任务发起者而言，也不会出现任务执行过程中，客户端越来越少的情况。

那么我们将一个select -> map -> aggregate -> reduce的过程，称为一轮，也就是一个Round。 一个横向联邦计算任务的流程，就可以抽象为多个Round，也就是：

Start -> Round 1 -> Round 2 -> ... -> Round N -> Finish

当然，一个完整的横向联邦计算任务，除了流程之外，还应该包含输入和输出。任务的输入，可以分为两类:

1. 一类是外部的输入，也就是各个客户端 持有的数据，这些数据，在任务定义的过程中并不能获取到他们的值，只能在运行时获取，因此在定义任务时，要采用声明式的方式来定义这些输入；
2. 另一类是任务自带的输入，比如说联邦学习中模型的初始权重，联邦统计中用户使用的一些常量、字面量等，这些值在定义任务时，值就已经明确了。

关于任务的输出，不同的任务类型，有不同的输出。具体来说，联邦学习任务的输出就是固定的，是训练好的模型权重；联邦统计的任务输出就不固定了， 用户在编写任务时，可以根据需要来定义不同的任务输出。但是有一点需要注意的是，任务最后的输出一定要是安全的，不能泄露客户端数据的隐私， 也就是说，最后输出的值一定是要通过reduce操作生成的、“归并”过的值。

所以，对于Delta来说，需要做的就是将用户编写的任务逻辑代码（横向联邦学习，横向联邦统计），转化为上述的一个又一个Round的形式， 并实现相应的客户端、服务端和安全聚合算法，用来执行每个Round中的map、reduce、aggregate和select操作。
